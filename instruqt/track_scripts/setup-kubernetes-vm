#!/bin/bash

####################################################################### WAIT

echo "Wait for the Instruqt host bootstrap to finish"
# Wait for the Instruqt host bootstrap to finish
while [ ! -f /opt/instruqt/bootstrap/host-bootstrap-completed ]
do
    echo "Waiting for Instruqt to finish booting the virtual machine"
    sleep 1
done

# explicitly source env vars
source /etc/profile.d/instruqt-env.sh

####################################################################### ENV CHECK

export _SANDBOX_ID=$_SANDBOX_ID
export INSTRUQT=$INSTRUQT
export LLM_KEY_DURATION=$LLM_KEY_DURATION
export LLM_KEY_MAX_BUDGET=$LLM_KEY_MAX_BUDGET
export LLM_MODELS=$LLM_MODELS
export LLM_PROXY_URL=$LLM_PROXY_URL
export SA_LLM_PROXY_BEARER_TOKEN=$SA_LLM_PROXY_BEARER_TOKEN
export GCSKEY_ELASTIC_SA=$GCSKEY_ELASTIC_SA
export GCSKEY_EDEN_WORKSHOP=$GCSKEY_EDEN_WORKSHOP
export GCS_KEY_EDUCATION=$GCS_KEY_EDUCATION
export GCSKEY=$GCSKEY

if [[ -z "$_SANDBOX_ID" ]]; then
    echo "_SANDBOX_ID is null"
    exit 1
else
    echo "_SANDBOX_ID=$_SANDBOX_ID"
fi

if [[ -z "$INSTRUQT" ]]; then
    echo "INSTRUQT is null"
    exit 1
else
    echo "INSTRUQT=$INSTRUQT"
fi

if [[ -z "$LLM_KEY_DURATION" ]]; then
    echo "LLM_KEY_DURATION is null"
    exit 1
else
    echo "LLM_KEY_DURATION=$LLM_KEY_DURATION"
fi

if [[ -z "$LLM_KEY_MAX_BUDGET" ]]; then
    echo "LLM_KEY_MAX_BUDGET is null"
    exit 1
else
    echo "LLM_KEY_MAX_BUDGET=$LLM_KEY_MAX_BUDGET"
fi

if [[ -z "$LLM_MODELS" ]]; then
    echo "LLM_MODELS is null"
    exit 1
else
    echo "LLM_MODELS=$LLM_MODELS"
fi

if [[ -z "$LLM_PROXY_URL" ]]; then
    echo "LLM_PROXY_URL is null"
    exit 1
else
    echo "LLM_PROXY_URL=$LLM_PROXY_URL"
fi

if [[ -z "$SA_LLM_PROXY_BEARER_TOKEN" ]]; then
    echo "SA_LLM_PROXY_BEARER_TOKEN is null"
    exit 1
fi
if [[ -z "$GCSKEY_ELASTIC_SA" ]]; then
    echo "GCSKEY_ELASTIC_SA is null"
    exit 1
fi
if [[ -z "$GCSKEY_EDEN_WORKSHOP" ]]; then
    echo "GCSKEY_EDEN_WORKSHOP is null"
    exit 1
fi
if [[ -z "$GCSKEY" ]]; then
    echo "GCSKEY is null"
    exit 1
fi

####################################################################### STARTUP

# finish elastic install
source /opt/workshops/elastic-start.sh

# Set Elasticsearch connection variables (may be set by elastic-start.sh, but ensure defaults)
ELASTICSEARCH_URL="${ELASTICSEARCH_URL:-http://localhost:30920}"
ELASTICSEARCH_APIKEY="${ELASTICSEARCH_APIKEY:-${ELASTIC_API_KEY}}"

# Force Elasticsearch to reload secure settings to pick up GCS credentials
# This prevents the 4.5 minute retry loop waiting for keystore propagation
echo "[Workshop] Reloading secure settings to pick up GCS credentials..."
curl -s -X POST "${ELASTICSEARCH_URL}/_nodes/reload_secure_settings" \
  -H "Authorization: ApiKey ${ELASTICSEARCH_APIKEY}" \
  -H "Content-Type: application/json" >/dev/null 2>&1 || true
sleep 20  # Allow keystore to fully propagate before snapshot restore

# Restore snapshot with product catalog, reviews, and clickstream data
echo "[Workshop] Restoring Elasticsearch snapshot..."
/opt/workshops/elastic-snapshot.sh \
    -p wayfinder_supply_co \
    -b instruqt-workshop-snapshot-public \
    -c sa \
    -n repo1 \
    -s catalog_reviews_clicks \
    -g false || {
    echo "[Workshop] ⚠️  Could not restore snapshot, continuing..."
}

# setup openai
source /opt/workshops/llm-key.sh

####################################################################### WAIT FOR K3S API

export KUBECONFIG=/etc/rancher/k3s/k3s.yaml

wait_for_api() {
  local timeout="$1"
  echo "[k3s] Waiting for API server readiness (timeout ${timeout}s)..."
  for i in $(seq 1 "$timeout"); do
    if kubectl get --raw='/readyz' >/dev/null 2>&1; then
      echo "[k3s] API server is responding"
      return 0
    fi
    sleep 1
  done
  return 1
}

if ! wait_for_api 300; then
  echo "[k3s] API not ready after first wait; restarting k3s once..."
  sudo systemctl restart k3s || true
  sleep 5
  if ! wait_for_api 180; then
    echo "[k3s] ERROR: API server not ready after restart"
    exit 1
  fi
fi

echo "[k3s] Waiting for nodes to become Ready..."
kubectl wait --for=condition=Ready node --all --timeout=300s

####################################################################### CONFIGURE KIBANA

echo "[Workshop] Configuring Kibana publicBaseUrl..."
kubectl patch kibana kibana -n default --type=merge -p '{
  "spec": {
    "config": {
      "server.publicBaseUrl": "http://kubernetes-vm:30001"
    }
  }
}' 2>/dev/null || echo "[Workshop] ⚠️  Could not patch Kibana config"

####################################################################### WAIT FOR KIBANA AND ENABLE WORKFLOWS FEATURE FLAG

echo "[Workshop] Waiting for Kibana to be ready..."
MAX_RETRIES=60
RETRY_COUNT=0

KIBANA_URL_UI="${KIBANA_URL_UI:-${KIBANA_URL:-http://localhost:30001}}"
ELASTICSEARCH_APIKEY="${ELASTICSEARCH_APIKEY:-${ELASTIC_API_KEY}}"

until curl -fsS -H "Authorization: ApiKey ${ELASTICSEARCH_APIKEY}" "${KIBANA_URL_UI}/api/status" >/dev/null 2>&1; do
  RETRY_COUNT=$((RETRY_COUNT + 1))
  if [ $RETRY_COUNT -ge $MAX_RETRIES ]; then
    echo "[Workshop] ERROR: Kibana did not become ready in time"
    exit 1
  fi
  echo "  ... waiting for Kibana (attempt ${RETRY_COUNT}/${MAX_RETRIES})"
  sleep 5
done

echo "[Workshop] ✓ Kibana is ready"

# Enable workflows feature flag and dark mode
echo "[Workshop] Enabling workflows feature flag and dark mode..."
FEATURE_FLAG_RESPONSE=$(curl -s -w "\n%{http_code}" -X POST "${KIBANA_URL_UI}/api/kibana/settings" \
  -H "Content-Type: application/json" \
  -H "kbn-xsrf: true" \
  -H "x-elastic-internal-origin: featureflag" \
  -H "Authorization: ApiKey ${ELASTICSEARCH_APIKEY}" \
  -d '{
    "changes": {
      "workflows:ui:enabled": true,
      "theme:darkMode": true
    }
  }')

HTTP_CODE=$(echo "$FEATURE_FLAG_RESPONSE" | tail -n1)
if [ "$HTTP_CODE" = "200" ] || [ "$HTTP_CODE" = "204" ]; then
  echo "[Workshop] ✓ Workflows feature flag and dark mode enabled"
else
  echo "[Workshop] ⚠️  Warning: Feature flag API returned HTTP $HTTP_CODE"
fi

export KIBANA_URL="${KIBANA_URL_UI}"
export ELASTICSEARCH_URL="${ELASTICSEARCH_URL:-http://localhost:30920}"
export ELASTICSEARCH_APIKEY="${ELASTICSEARCH_APIKEY}"

####################################################################### DOWNLOAD WORKSHOP ASSETS

echo "[Workshop] Downloading workshop assets from GitHub..."
cd /opt
rm -rf workshop-assets temp-repo
mkdir -p workshop-assets

echo "[Workshop] Cloning repository..."
if git clone --depth 1 https://github.com/jeffvestal/wayfinder_supply_co.git temp-repo; then
  echo "[Workshop] ✓ Repository cloned successfully"
  
  echo "[Workshop] Copying scripts and config directories..."
  if [ -d "temp-repo/scripts" ]; then
    cp -r temp-repo/scripts /opt/workshop-assets/
    echo "[Workshop] ✓ Copied scripts directory"
  else
    echo "[Workshop] ✗ ERROR: scripts directory not found in repo!"
    ls -la temp-repo/
  fi
  
  if [ -d "temp-repo/config" ]; then
    cp -r temp-repo/config /opt/workshop-assets/
    echo "[Workshop] ✓ Copied config directory"
  else
    echo "[Workshop] ✗ ERROR: config directory not found in repo!"
  fi
  
  rm -rf temp-repo
  echo "[Workshop] ✓ Cleaned up temp-repo"
else
  echo "[Workshop] ✗ ERROR: Could not clone repository!"
fi

echo "[Workshop] Workshop assets directory contents:"
ls -la /opt/workshop-assets/

if [ -d "/opt/workshop-assets/scripts" ]; then
  echo "[Workshop] Scripts directory contents:"
  ls -la /opt/workshop-assets/scripts/
fi

if [ -d "/opt/workshop-assets/config" ]; then
  echo "[Workshop] Config directory contents:"
  ls -la /opt/workshop-assets/config/
fi

####################################################################### SETUP ELASTICSEARCH INDICES

# Indices are restored from snapshot, no need to create them
echo "[Workshop] Elasticsearch indices restored from snapshot"

####################################################################### CREATE LLM CONNECTOR

echo "[Workshop] Creating LLM connector..."

kibana_post() {
  local endpoint="$1"
  local body="$2"
  curl -s -w "\n%{http_code}" -X POST "${KIBANA_URL_UI}${endpoint}" \
    -H "Content-Type: application/json" \
    -H "kbn-xsrf: true" \
    -H "Authorization: ApiKey ${ELASTICSEARCH_APIKEY}" \
    -d "$body"
}

CONNECTOR_ID=""
MAX_RETRIES=5
RETRY_COUNT=0

while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
  RETRY_COUNT=$((RETRY_COUNT + 1))
  echo "[Workshop] Attempting to create LLM connector (attempt ${RETRY_COUNT}/${MAX_RETRIES})..."
  
  RESPONSE=$(kibana_post "/api/actions/connector" '{
    "name": "Elastic Proxy LLM",
    "config": {
      "apiProvider": "OpenAI",
      "apiUrl": "https://'"${LLM_PROXY_URL}"'/v1/chat/completions",
      "defaultModel": "gpt-4.1"
    },
    "secrets": {
      "apiKey": "'"${LLM_APIKEY}"'"
    },
    "connector_type_id": ".gen-ai"
  }')
  
  HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
  BODY=$(echo "$RESPONSE" | sed '$d')
  
  if [ "$HTTP_CODE" = "200" ] || [ "$HTTP_CODE" = "201" ]; then
    CONNECTOR_ID=$(echo "$BODY" | grep -o '"id":"[^"]*"' | head -1 | cut -d'"' -f4)
    if [ -n "$CONNECTOR_ID" ]; then
      echo "[Workshop] ✓ LLM connector created (ID: ${CONNECTOR_ID})"
      break
    fi
  elif [ "$HTTP_CODE" = "409" ]; then
    echo "[Workshop] Connector already exists, discovering..."
    LIST_RESPONSE=$(curl -s -X GET "${KIBANA_URL_UI}/api/actions/connectors" \
      -H "kbn-xsrf: true" \
      -H "Authorization: ApiKey ${ELASTICSEARCH_APIKEY}")
    CONNECTOR_ID=$(echo "$LIST_RESPONSE" | python3 -c "
import sys, json
try:
    data = json.load(sys.stdin)
    for conn in data.get('data', []):
        if conn.get('name') == 'Elastic Proxy LLM':
            print(conn.get('id', ''))
            break
except:
    pass
" 2>/dev/null)
    if [ -n "$CONNECTOR_ID" ]; then
      echo "[Workshop] ✓ Found existing connector (ID: ${CONNECTOR_ID})"
      break
    fi
  else
    if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
      echo "[Workshop] Retrying in 2 seconds..."
      sleep 2
    fi
  fi
done

if [ -n "$CONNECTOR_ID" ]; then
  echo "[Workshop] Setting connector as default..."
  curl -s -X POST "${KIBANA_URL_UI}/internal/kibana/settings" \
    -H "Content-Type: application/json" \
    -H "kbn-xsrf: true" \
    -H "x-elastic-internal-origin: featureflag" \
    -H "Authorization: ApiKey ${ELASTICSEARCH_APIKEY}" \
    -d '{
      "changes": {
        "genAiSettings:defaultAIConnector": "'"${CONNECTOR_ID}"'"
      }
    }' >/dev/null 2>&1
fi

####################################################################### SETUP PYTHON FOR AGENT/WORKFLOW CREATION

echo "[Workshop] Setting up Python environment for agent creation..."
cd /opt/workshop-assets

echo "[Workshop] Creating Python virtual environment..."
python3 -m venv venv
source venv/bin/activate

echo "[Workshop] Python version: $(python3 --version)"
echo "[Workshop] Installing Python dependencies..."
pip install --upgrade pip
pip install pyyaml requests python-dotenv elasticsearch

# Write environment file
echo "[Workshop] Writing environment file..."
cat > /opt/workshop-assets/.env << EOF
ELASTICSEARCH_URL=${ELASTICSEARCH_URL}
KIBANA_URL=${KIBANA_URL}
ELASTICSEARCH_APIKEY=${ELASTICSEARCH_APIKEY}
EOF

echo "[Workshop] Environment variables for scripts:"
echo "  ELASTICSEARCH_URL=${ELASTICSEARCH_URL}"
echo "  KIBANA_URL=${KIBANA_URL}"
echo "  ELASTICSEARCH_APIKEY=<redacted>"

####################################################################### DEPLOY WORKFLOWS

echo "[Workshop] ========================================"
echo "[Workshop] DEPLOYING WORKFLOWS"
echo "[Workshop] ========================================"

if [ -d "/opt/workshop-assets/scripts" ]; then
  cd /opt/workshop-assets/scripts
  echo "[Workshop] Current directory: $(pwd)"
  
  if [ -f "deploy_workflows.py" ]; then
    echo "[Workshop] Found deploy_workflows.py, executing..."
    
    # Check if config/workflows exists
    if [ -d "/opt/workshop-assets/config/workflows" ]; then
      echo "[Workshop] Workflow config directory found:"
      ls -la /opt/workshop-assets/config/workflows/
    else
      echo "[Workshop] ⚠️  WARNING: /opt/workshop-assets/config/workflows not found!"
    fi
    
    ELASTICSEARCH_URL="${ELASTICSEARCH_URL}" \
    KIBANA_URL="${KIBANA_URL}" \
    ELASTICSEARCH_APIKEY="${ELASTICSEARCH_APIKEY}" \
    python3 deploy_workflows.py --workflows-dir /opt/workshop-assets/config/workflows --exclude get_customer_profile 2>&1 || {
      echo "[Workshop] ⚠️  Workflow deployment returned non-zero exit code"
    }
  else
    echo "[Workshop] ✗ deploy_workflows.py not found at $(pwd)"
    ls -la
  fi
else
  echo "[Workshop] ✗ ERROR: /opt/workshop-assets/scripts directory does not exist!"
fi

####################################################################### CREATE AGENTS AND TOOLS

echo "[Workshop] ========================================"
echo "[Workshop] CREATING AGENTS AND TOOLS"
echo "[Workshop] ========================================"

if [ -d "/opt/workshop-assets/scripts" ]; then
  cd /opt/workshop-assets/scripts
  echo "[Workshop] Current directory: $(pwd)"
  
  if [ -f "create_agents.py" ]; then
    echo "[Workshop] Found create_agents.py, executing..."
    
    ELASTICSEARCH_URL="${ELASTICSEARCH_URL}" \
    KIBANA_URL="${KIBANA_URL}" \
    ELASTICSEARCH_APIKEY="${ELASTICSEARCH_APIKEY}" \
    python3 create_agents.py --skip-workflows get_customer_profile --skip-tools tool-workflow-get-customer-profile --skip-agents trip-planner-agent 2>&1 || {
      echo "[Workshop] ⚠️  Agent creation returned non-zero exit code"
    }
  else
    echo "[Workshop] ✗ create_agents.py not found at $(pwd)"
    ls -la
  fi
else
  echo "[Workshop] ✗ ERROR: /opt/workshop-assets/scripts directory does not exist!"
fi

deactivate
echo "[Workshop] Deactivated Python virtual environment"

####################################################################### WARM UP ELSER MODEL (BACKGROUND)

echo "[Workshop] Starting ELSER model warmup in background..."
echo "[Workshop] (Track can start while model loads; first semantic search may be slightly slower)"

# Background the ELSER warmup so it doesn't block track startup
# Use nohup and disown to ensure script exits immediately without waiting
nohup bash -c '
  # Wait for ELSER to be ready with retries
  # The model needs time to deploy and load into memory
  ELSER_MAX_RETRIES=24  # 24 retries x 5 seconds = 2 minutes max wait
  ELSER_RETRY_COUNT=0
  ELSER_READY=false

  while [ $ELSER_RETRY_COUNT -lt $ELSER_MAX_RETRIES ]; do
    # Use .elser-2-elasticsearch (local ML node for search), NOT .elser-2-elastic (Elastic Cloud ingest)
    ELSER_RESPONSE=$(curl -s -X POST "${ELASTICSEARCH_URL}/_inference/sparse_embedding/.elser-2-elasticsearch" \
      -H "Authorization: ApiKey ${ELASTICSEARCH_APIKEY}" \
      -H "Content-Type: application/json" \
      -d "{\"input\": \"outdoor hiking gear\"}" 2>&1)
    
    # Check if we got tokens back (successful warmup)
    if echo "$ELSER_RESPONSE" | grep -q "sparse_embedding"; then
      ELSER_READY=true
      echo "[Workshop] ✓ ELSER model warmed up and ready for instant semantic search"
      break
    fi
    
    ELSER_RETRY_COUNT=$((ELSER_RETRY_COUNT + 1))
    echo "[Workshop]   ELSER model loading... (attempt $ELSER_RETRY_COUNT/$ELSER_MAX_RETRIES)"
    sleep 5
  done

  if [ "$ELSER_READY" != true ]; then
    echo "[Workshop] ⚠️  ELSER model still loading after 2 minutes"
    echo "[Workshop]     First semantic search may be slow, but will work"
  fi
' > /var/log/elser-warmup.log 2>&1 & disown

echo "[Workshop] ELSER warmup running in background (check /var/log/elser-warmup.log for progress)"

####################################################################### COMPLETE

echo "========================================="
echo "[Workshop] kubernetes-vm setup complete"
echo "========================================="
echo "Services:"
echo "  - Elasticsearch: ${ELASTICSEARCH_URL}"
echo "  - Kibana: ${KIBANA_URL}"
echo ""
echo "Created:"
echo "  - Workflows (check_trip_safety, get_user_affinity, extract_trip_entities)"
echo "  - Tools (product_search, ES|QL queries, workflow tools)"
echo "  - Agents (context-extractor, response-parser, itinerary-extractor, trip-itinerary)"
echo ""
echo "Note: Learners will build in workshops:"
echo "  - get_customer_profile workflow (Challenge 2)"
echo "  - tool-workflow-get-customer-profile (Challenge 3)"
echo "  - trip-planner-agent (Challenge 4)"
echo "========================================="


